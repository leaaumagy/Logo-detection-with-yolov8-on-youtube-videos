{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8jfZgZRmXLUi",
      "metadata": {
        "id": "8jfZgZRmXLUi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "643c5793-18da-4e80-875f-d53da4f92a30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.0.235-py3-none-any.whl (677 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m677.8/677.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.16.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Collecting thop>=0.1.1 (from ultralytics)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.47.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2023.11.17)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: thop, ultralytics\n",
            "Successfully installed thop-0.1.1.post2209072238 ultralytics-8.0.235\n",
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.66.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.5.16)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.7)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.31.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.6)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n",
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.23.5)\n",
            "Installing collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n",
            "Collecting ffmpeg\n",
            "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: ffmpeg\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6080 sha256=961e7302cad61906bab02af6652a2865691e797531d6ac6baa4704a0e45f9f79\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/7a/69/cd6aeb83b126a7f04cbe7c9d929028dc52a6e7d525ff56003a\n",
            "Successfully built ffmpeg\n",
            "Installing collected packages: ffmpeg\n",
            "Successfully installed ffmpeg-1.4\n"
          ]
        }
      ],
      "source": [
        "!pip3 install ultralytics\n",
        "!pip3 install opendatasets\n",
        "!pip3 install pytube opencv-python\n",
        "!pip3 install ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "b673ca19-5550-4d24-b174-f96deca941a1",
      "metadata": {
        "id": "b673ca19-5550-4d24-b174-f96deca941a1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "from IPython import display\n",
        "from ultralytics import YOLO\n",
        "import opendatasets as od\n",
        "import xml.etree.ElementTree as ET\n",
        "from pytube import YouTube\n",
        "import cv2\n",
        "import requests\n",
        "import subprocess\n",
        "from glob import glob\n",
        "import random\n",
        "import yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01dff38b-4f3c-4627-87c5-35372a74d83d",
      "metadata": {
        "id": "01dff38b-4f3c-4627-87c5-35372a74d83d"
      },
      "source": [
        "## Download training images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "fdb4cc3c-df05-49c7-830d-7eada469ca86",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdb4cc3c-df05-49c7-830d-7eada469ca86",
        "outputId": "28df88a7-d6cc-48b9-b139-93063d4742e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: leaaumagy\n",
            "Your Kaggle Key: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Downloading logodet3k.zip to ./logodet3k\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.87G/2.87G [00:39<00:00, 78.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "od.download(\"https://www.kaggle.com/datasets/lyly99/logodet3k\")\n",
        "# you must have a kaggle account and generate your api in the settings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f2c8d59-9642-482d-ae05-772a64a36ad3",
      "metadata": {
        "id": "2f2c8d59-9642-482d-ae05-772a64a36ad3"
      },
      "source": [
        "## Copy the 'Clothes' folder to a new 'Dataset' folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "09482a3c-8086-4621-ba97-fabe2322116b",
      "metadata": {
        "id": "09482a3c-8086-4621-ba97-fabe2322116b"
      },
      "outputs": [],
      "source": [
        "def copy_and_rename(folder_path, destination_path):\n",
        "    # Copy the \"Clothes\" folder to the new \"Dataset\" folder\n",
        "    shutil.copytree(folder_path, os.path.join(destination_path))\n",
        "\n",
        "# Path of the 'Clothes' folder\n",
        "folder_path = '/content/logodet3k/LogoDet-3K/Clothes'\n",
        "\n",
        "# Path of the destination folder\n",
        "destination_path = '/content/Dataset/Clothes'\n",
        "\n",
        "# Call the function to copy\n",
        "copy_and_rename(folder_path, destination_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tb_YA6ckYh8r",
      "metadata": {
        "id": "tb_YA6ckYh8r"
      },
      "source": [
        "## Rename brand folder names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "loweOuZHYZet",
      "metadata": {
        "id": "loweOuZHYZet"
      },
      "outputs": [],
      "source": [
        "def rename_folders(directory_path):\n",
        "    # List all items in the directory\n",
        "    items = os.listdir(directory_path)\n",
        "\n",
        "    for item in items:\n",
        "        item_path = os.path.join(directory_path, item)\n",
        "\n",
        "        # Check if the item is a folder\n",
        "        if os.path.isdir(item_path):\n",
        "            # Rename the folder by replacing spaces with underscores\n",
        "            new_name = item.replace(\" \", \"_\")\n",
        "            new_name = new_name.replace(\"76\", \"A_76\")\n",
        "            new_name = new_name.replace(\"-\", \"_\")\n",
        "            new_name = new_name.replace(\"'\", \"_\")\n",
        "            new_path = os.path.join(directory_path, new_name)\n",
        "            os.rename(item_path, new_path)\n",
        "\n",
        "# Directory to be processed\n",
        "directory_to_process = '/content/Dataset/Clothes'\n",
        "rename_folders(directory_to_process)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "o5eyaAbD-LCM",
      "metadata": {
        "id": "o5eyaAbD-LCM"
      },
      "source": [
        "## Filter on selected brands"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "n1qv69Fu-JDX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1qv69Fu-JDX",
        "outputId": "0d2df7b0-9dcd-496d-8752-01f3195bd9f3",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List of all files and folders in 'Clothes':\n",
            "['tiffany', 'stussy', 'loro_piana', 'Adidas_SB', 'Celine', 'Man_O__War', 'adyson', 'Ariat', 'Capezio', 'AOKANG', 'Armani_Exchange', 'Altra', 'American_Apparel', 'Acne_Studios', 'Herschel_Supply', 'sansabelt', 'norrona', 'Anne_Klein', 'Andrew_Marc', 'pajar', 'oris', 'vivobarefoot_2', 'new_balance_1', 'new_balance_2', 'miu_miu', 'Clarks', 'Bulgari', 'Boscov_s', 'youngor_2', 'superga_2', 'Covert', 'mido', 'topman', 'Carhartt', 'Grundies', 'EKCO', 'Everlast', 'gigo', 'brace_yourself', 'rocky', 'Audemars_Piguet', 'wolford', '7_PE', 'Imperial', 'Josef_Seibel', 'Adriatica', 'marchesa', 'maui_jim', 'Guy_Laroche', 'Kiton', 'Chippewa', 'moncler_2', 'Hoka_One_One', 'wrangler', 'majestic', 'zara', 'rapha', 'Admiral', 'Galvin_Green', 'u.s._polo_assn', 'swatch', 'Kenneth_Cole', 'Guess', 'A._Favre_&_Fils', 'sanuk', 'Andrew_Christian', 'Bulova', 'pythia', 'corneliani', 'chaps', 'zingara', 'Boxfresh', 'triumph_1', 'Chipotle_Mexican_Grill_2', 'youngor_3', 'sergio_tacchini', 'ERKE_1', 'Alchemist', 'movado', 'Bosideng', 'Circa', 'Bunker', 'eBags', 'gunnar', 'Bella_Vita', 'nicole_lee_1', 'tyr', 'perlina', 'Intymen', 'vince_camuto_1', 'rax', 'simon', 'lang_sha', 'Betty_Crocker', 'wonderbra', 'starbury_1', 'BUCO', 'Aerosoles', 'louis_vuitton_1', 'KATE_SPADE_2', 'AKOO', 'loewe', 'lacoste', 'Hurley_International', 'viso', 'zodiac', 'Eileen_Fisher', 'jlindeberg_2', 'sonia_rykiel', 'sperry_top_sider', 'Canterbury', 'Geographics', 'Alfred_Dunhill', 'Errea', 'scottevest', 'technomarine', 'superga_1', 'marni', 'scotch_and_soda', 'Isabel_Maran_1', 'Knomo', 'Ermenegildo_Zegna', 'moncler_1', 'satya_paul', 'A_76', 'Baggallini', 'charlotte_olympia', 'Heat_2', 'Injinji', 'nasty_pig_2', 'Ergowear', 'Aquascutum', 'CaiBai', 'tudor', 'Ella_Moss', 'Barcode_Berlin', 'Kathmandu', 'cartelo', 'starter', 'lucky_brand', 'ping', 'pony', 'r._m._williams', 'penfield', 'Allen_Edmonds', 'yinshidai', 'Glock_1', 'Harry_Winston_2', 'Captain_Planet', 'viennois', 'r_&_r_collections', 'moving_comfort_1', 'miss_sixty', 'pacsafe', 'pvh', 'steve_madden', 'titan_industries', 'tom_tailor', 'Calvin_Klein_Underwear', 'Burlington_Coat_Factory', 'panerai', 'Christian_Louboutin', 'stowa', 'Izod', 'petzl', 'prada', 'wolky', 'Bare_Necessities', 'Champion', 'ryb', 'Hurley_2', 'aussieBum', '3D_GOLD', 'krink', 'Carlo_Ferrara', 'Alfani', 'Kenzo', 'sophie_paris', '2xist', 'C_IN2', 'naot', 'Coldwater_Creek', 'Betsey_Johnson', 'nina_ricci', 'Chiquita', 'Gul', 'Emilio', 'nanjiren', 'yuzhaolin', 'levis', 'pierre_cardin', 'Gap', 'uniqlo', 'septwolves', 'Era', 'strellson', 'royce_leather', 'zaya', 'Baci_Lingerie', 'vision_street_wear', 'alpinestars_2', 'oroton', 'Ck_Calvin_Klein_1', 'skiny', 'spring_step', 'smythson', 'KELA', 'Black_eyed_Pea', 'luminox', 'tommy_bahama', 'Blondo', 'KAIER', 'Kavu', 'zero_halliburton', 'Faconnable', 'sanita', 'missoni', 'muzak_2', 'scarpa', 'lonsdale', 'playboy', 'naturalizer_2', 'xoxo', 'Frankie_Morello', 'ANNICK_GOUTAL', 'oxxford', 'HOM', 'Campmor', 'max_mara', 'saks_fifth_avenue', 'superfeet', 'the_timberland', 'samsonite', 'muzak_1', 'French_Connection', 'AND1', 'Cesare_Paciotti', 'Heavy_Eco', 'Giorgio', 'Frank_Dandy', 'brine', 'AIMER', 'looptworks', 'MARC_BY_MARC_JACOBS', 'vivobarefoot_1', 'Cacharel', 'voit', 'Hurley_1', 'marc_o_polo', 'FUBU', 'MBT', 'phat_farm', 'KooGa', 'Golite', 'Cocksox', 'Crumpler', 'supawear', 'Canada_Goose', 'Abercrombie_&_Fitch', 'rochas', 'Black_Label_Skateboards', 'Head', '4Skins', 'Athletic_DNA', 'orvis', 'Hanes', 'Ahnu', 'Haglofs', 'American_Eagle', 'mitre', 'Atletica', 'whataburger_1', 'Freegun', 'tiger_of_sweden', 'otto_versand', 'meyba_2', 'pirma', 'Bootights', 'Agnes_b', 'luscious_pink', 'Goya', 'pequignet', 'clement', 'Balenciaga', 'Chrome_Hearts', 'Berghaus', 'Caslon', 'shure', 'bobble', 'the_flexx', 'ANTA', 'CDELALA', 'chaya', 'patagonia', 'rare', 'roberto_cavalli', 'alpinestars_1', 'l.l.bean', 'Antony_Morato', 'ERKE_2', 'skins', 'meters_bonwe', 'Anna_Sui', 'pikante', 'Ck_Calvin_Klein_2', 'under_armour', 'pepe_jeans', 'Joe_Fresh', 'Blundstone', 'rockport', 'Emerica', 'regatta', 'Casio', 'bukta', 'charlotte_russe', 'Karl_Kani_1', 'sorel', 'Emilio_Pucci', 'ERAL', 'Balmain', 'peebles', 'Chooka', 'Carbrini', 'kookaburra', 'simond', 'Bjorn_Borg', 'minnetonka', 'Los_Angeles', 'reusch', 'jlindeberg_1', 'sumdex', 'jianjiang', 'Harry_Winston_1', 'youngor_1', 'stacy_adams_2', 'Heckler_&_Koch', 'Kookai', 'sergio_rossi', 'Guy_Cotten', 'Columbia', 'Converse', 'conlia', 'qipai', 'valentino_s', 'John_Richmond', 'muchachomalo', 'JOULES', 'Invicta', 'atari_2600_2', 'Ayilian', 'versace', 'kasumi', 'whataburger_2', 'moving_comfort_2', 'atari_2600_1', 'the_original_muck_boot_company', 'patek_philippe', 'mephisto', 'triumph_2', 'Ben_Davis', 'InterCall', 'marina_rinaldi', 'Christian_Lacroix', 'pf_flyers', 'BeautiFeel', 'vaneli', 'Frye', 'Barneys_New_York', 'Bloomingdale_s', 'Hoya', 'orient', 'montane', 'zino', 'Airness', 'Hanro', 'Care_Bears', 'amnesia', 'Baume_et_Mercier_1', 'mountain_hardwear', 'Badgley_Mischka', 'HBC', 'sakroots', 'KATE_SPADE_1', 'Bostonian', 'Joma_2', 'Ecko_Unltd', 'Bottega_Veneta', 'chilewich', 'BeiJiRong', 'rodania', 'Joma_1', 'antonio', 'Bob_Evans_Restaurants', 'Eddie_Bauer', 'Hilleberg', 'rolex', 'Acqua_Limone', 'tarocash', 'Aristoc', 'Chipotle_Mexican_Grill_1', 'spiewak', 'FUCT', 'KaZhuMi', 'williams_sonoma', 'luciano_soprani', 'petronor', 'he_man', 'tom_ford', 'L.K.Bennett', 'ryka', '66_North', 'spanx', 'Barbie', 'Etro', 'yoko', 'Armani_Junior', 'softspots', 'lanidor', 'soffe', 'Baume_et_Mercier_2', 'ow_lee', 'Hummel_1', 'rieker', 'mesa_boogie', 'seven_fathoms', 'nicole_lee_2', 'mandarina_duck', 'seavees', 'roamer', 'propet', 'Isabel_Maran_2', 'Freya', 'Church_s', 'stacy_adams_1', 'mossimo', 'star_in_the_hood', 'vince_camuto_2', 'piado', 'panoz', 'sparco', 'Birki_s', 'old_navy', 'Heat_1', 'ugg_australia', 'Addicted', 'rudsak', 'obey', 'Breitling', 'Karhu', 'Chopard', 'Georg_Jensen', 'titoni', 'Exofficio', 'Glock_2', 'six_deuce', 'seagull', 'regina', 'timex', 'la_miu', 'fox_river_mills', 'Aritzia', 'pausa', 'qeelin', 'tommy_hilfiger', 'timbuk2_1', 'Ed_Hardy', 'Hugo_Boss', 'BALENO', 'starbury_2', 'garanimals', 'mexx', 'Calvin_Klein', 'ruans', 'meyba_1', 'timberland', 'A.P.C', 'gumby', 'Gibson', 'spenco', 'oriocx', 'osprey', 'Boboli', 'Akris', 'Churchkey_Can', 'speedplay', 'trangoworld', 'Georgia_Boot', 'Earthies', 'tilted_kilt', 'vionic', 'Hush_Puppies', 'wesc', 'charming_charlie', 'timbuk2_2', 'Kelty', 'saxx', 'sofft', 'paddy_pallin', 'polo_ralph_lauren', 'BOSE', 'montagu', 'Arri', 'peak_performance', 'Etnies', 'Armani', 'La_Perla', 'Manhattan_Portage', 'French_Sole', 'Bestseller', 'Bill_Blass', 'Aigle', 'otz_shoes', 'shg', 'louis_vuitton_2', 'rioni', 'tissot', 'penalty', 'Elder_Beerman', 'John_Varvatos', 'Allrounder', 'British_Knights', 'the_north_face', 'Bonia', 'Ceceba', 'peace_bird', 'yishion', 'moonbasa', 'hubba_wheels', 'charles_owo', 'John_Galliano', 'Karl_Lagerfeld', 'oryany', 'vibram', 'Hummel_2', 'Atticus', 'Ellesse', 'Excelsior', 'woolrich', 'amy_butler', 'Abercrombie', 'itg', 'Alain_Figaret', 'sistema', 'Arc_teryx', 'Agacio', 'kensie', 'smartwool', 'paul_green', 'schiesser', 'salomon', 'skora', 'lesportsac', 'Gabor', 'rebecca_minkoff', 'Easy_Spirit', 'Arcopedico', 'seafolly', 'pejo', 'Ecco', 'habixiong', 'sergio_valente', 'vera_bradley', 'Aravon', 'suunto', 'naturalizer_1', 'osgoode_marley', 'Happy_Socks', 'new_era', 'nasty_pig_1', 'chanel', 'rado', 'Hammary', 'lyle', 'Bally_Shoe', 'Chloe', 'rab', 'salvatore_ferragamo', 'wildcountry', 'robert_allen', 'relic', 'Givova', 'Independent_Truck', 'Boconi', 'Helsport', 'ASPINAL_OF_LONDON', 'zoke', 'Beach_Bunny', 'seiko', 'sinaina', 'AFuBeiBei', 'Henri_Wintermans', 'maidenform', 'napapijri', 'Karl_Kani_2', 'Birkenstock', 'xtep', 'Alpina_Watches', 'Ermanno_Scervino', 'Chaco', 'Bonds', 'Bomber', 'sram', 'rvca', 'mansmiling']\n"
          ]
        }
      ],
      "source": [
        "# Path to the \"Clothes\" folder\n",
        "clothes_path = \"/content/Dataset/Clothes\"\n",
        "\n",
        "# Get the list of all files and folders in the \"Clothes\" folder\n",
        "all_items = os.listdir(clothes_path)\n",
        "\n",
        "# Display all file and folder names\n",
        "print(\"List of all files and folders in 'Clothes':\")\n",
        "print(all_items)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "nRcaPCwmADNc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRcaPCwmADNc",
        "outputId": "9da6ac01-654f-489f-fe92-0afbe14095b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered folders:\n",
            "['Adidas_SB', 'Celine', 'new_balance_1', 'new_balance_2', 'Bulgari', 'Carhartt', 'Everlast', 'zara', 'Guess', 'sergio_tacchini', 'louis_vuitton_1', 'lacoste', 'prada', 'Champion', 'Kenzo', 'levis', 'Gap', 'uniqlo', 'Ck_Calvin_Klein_1', 'oxxford', 'the_timberland', 'Giorgio', 'American_Eagle', 'Balenciaga', 'patagonia', 'Ck_Calvin_Klein_2', 'pepe_jeans', 'Casio', 'Columbia', 'Converse', 'versace', 'rolex', 'tom_ford', 'obey', 'tommy_hilfiger', 'Hugo_Boss', 'timberland', 'polo_ralph_lauren', 'Armani', 'louis_vuitton_2', 'the_north_face', 'Ellesse', 'chanel', 'Chloe', 'napapijri']\n",
            "Operation completed.\n"
          ]
        }
      ],
      "source": [
        "# Path to the \"Clothes\" folder\n",
        "clothes_path = \"/content/Dataset/Clothes\"\n",
        "\n",
        "# List of selected folders\n",
        "selected_folders = ['Adidas_SB', 'American_Eagle', 'Armani', 'Balenciaga',\n",
        "                    'Bulgari', 'Ck_Calvin_Klein_1',\n",
        "                    'Ck_Calvin_Klein_2', 'Canada Goose', 'Carhartt', 'Casio', 'Celine',\n",
        "                    'Champion', 'chanel', 'Chloe', 'Columbia', 'Converse',\n",
        "                    'Ellesse', 'Everlast', 'Gap', 'Giorgio', 'Guess',\n",
        "                    'Hugo_Boss', 'Karl_Lagerfield', 'Kenzo', 'lacoste', 'levis',\n",
        "                    'louis_vuitton_1', 'louis_vuitton_2', 'napapijri',\n",
        "                    'new_balance_1', 'new_balance_2', 'obey', 'oxxford', 'patagonia', 'pepe_jeans',\n",
        "                    'polo_ralph_lauren', 'prada', 'rolex', 'sergio_tacchini',\n",
        "                    'the_timberland', 'the_north_face', 'timberland', 'tommy_hilfiger', 'tom_ford',\n",
        "                    'uniqlo', 'versace', 'zara']\n",
        "\n",
        "# Get the list of all files and folders in the \"Clothes\" folder\n",
        "all_items = os.listdir(clothes_path)\n",
        "\n",
        "# Filter folders using the selected list\n",
        "filtered_folders = [folder for folder in all_items if os.path.isdir(os.path.join(clothes_path, folder)) and folder.lower() in [sf.lower() for sf in selected_folders]]\n",
        "\n",
        "# Display filtered folders\n",
        "print(\"Filtered folders:\")\n",
        "print(filtered_folders)\n",
        "\n",
        "# Iterate through all folders in the \"Clothes\" folder\n",
        "for folder in all_items:\n",
        "    folder_path = os.path.join(clothes_path, folder)\n",
        "\n",
        "    # Check if the folder is not in the list of selected folders\n",
        "    if folder.lower() not in [sf.lower() for sf in selected_folders] and os.path.isdir(folder_path):\n",
        "        # Remove the non-selected folder and its contents\n",
        "        shutil.rmtree(folder_path)\n",
        "\n",
        "print(\"Operation completed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b90d4d7-0161-4d0d-ae5c-0a6217e5576c",
      "metadata": {
        "id": "8b90d4d7-0161-4d0d-ae5c-0a6217e5576c"
      },
      "source": [
        "## Rename images and xml file names to avoid duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "be394f55-c7a2-4f0a-a411-1e054dc940ae",
      "metadata": {
        "id": "be394f55-c7a2-4f0a-a411-1e054dc940ae"
      },
      "outputs": [],
      "source": [
        "def rename_files(folder_path):\n",
        "    for root, dirs, files in os.walk(folder_path):\n",
        "        # Exclude non-numeric subdirectories\n",
        "        dirs = [d for d in dirs if d.isdigit()]\n",
        "\n",
        "        for file in files:\n",
        "            if file.endswith(\".jpg\") or file.endswith(\".xml\"):\n",
        "                # Get the parent folder number\n",
        "                parent_folder_name = os.path.basename(root)\n",
        "\n",
        "                # Build the new file name with the parent folder number\n",
        "                new_name = f\"{os.path.splitext(file)[0]}_{parent_folder_name}{os.path.splitext(file)[1]}\"\n",
        "\n",
        "                # Current file path\n",
        "                current_path = os.path.join(root, file)\n",
        "\n",
        "                # Build the new file path\n",
        "                new_path = os.path.join(root, new_name)\n",
        "\n",
        "                # Rename the file\n",
        "                os.rename(current_path, new_path)\n",
        "\n",
        "# Path of the 'Clothes' folder\n",
        "folder_path = '/content/Dataset/Clothes'\n",
        "\n",
        "# Call the function to rename files\n",
        "rename_files(folder_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8IbA630-p7uj",
      "metadata": {
        "id": "8IbA630-p7uj"
      },
      "source": [
        "## Balancing the number of instances between brands"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "Qjk-ejbDqgOj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qjk-ejbDqgOj",
        "outputId": "087657b0-26c7-4f26-84f2-f561e8432503",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The folder Adidas_SB contains 65 JPEG files and 65 XML files.\n",
            "The folder Celine contains 108 JPEG files and 108 XML files.\n",
            "The folder new_balance_1 contains 155 JPEG files and 155 XML files.\n",
            "The folder new_balance_2 contains 155 JPEG files and 155 XML files.\n",
            "The folder Bulgari contains 80 JPEG files and 80 XML files.\n",
            "The folder Carhartt contains 31 JPEG files and 31 XML files.\n",
            "The folder Everlast contains 55 JPEG files and 55 XML files.\n",
            "The folder zara contains 151 JPEG files and 151 XML files.\n",
            "The folder Guess contains 50 JPEG files and 50 XML files.\n",
            "The folder sergio_tacchini contains 22 JPEG files and 22 XML files.\n",
            "The folder louis_vuitton_1 contains 96 JPEG files and 96 XML files.\n",
            "The folder lacoste contains 55 JPEG files and 55 XML files.\n",
            "The folder prada contains 52 JPEG files and 52 XML files.\n",
            "The folder Champion contains 29 JPEG files and 29 XML files.\n",
            "The folder Kenzo contains 63 JPEG files and 63 XML files.\n",
            "The folder levis contains 76 JPEG files and 76 XML files.\n",
            "The folder Gap contains 45 JPEG files and 45 XML files.\n",
            "The folder uniqlo contains 66 JPEG files and 66 XML files.\n",
            "The folder Ck_Calvin_Klein_1 contains 29 JPEG files and 29 XML files.\n",
            "The folder oxxford contains 41 JPEG files and 41 XML files.\n",
            "The folder the_timberland contains 70 JPEG files and 70 XML files.\n",
            "The folder Giorgio contains 13 JPEG files and 13 XML files.\n",
            "The folder American_Eagle contains 72 JPEG files and 72 XML files.\n",
            "The folder Balenciaga contains 113 JPEG files and 113 XML files.\n",
            "The folder patagonia contains 98 JPEG files and 98 XML files.\n",
            "The folder Ck_Calvin_Klein_2 contains 29 JPEG files and 29 XML files.\n",
            "The folder pepe_jeans contains 60 JPEG files and 60 XML files.\n",
            "The folder Casio contains 33 JPEG files and 33 XML files.\n",
            "The folder Columbia contains 28 JPEG files and 28 XML files.\n",
            "The folder Converse contains 15 JPEG files and 15 XML files.\n",
            "The folder versace contains 33 JPEG files and 33 XML files.\n",
            "The folder rolex contains 69 JPEG files and 69 XML files.\n",
            "The folder tom_ford contains 17 JPEG files and 17 XML files.\n",
            "The folder obey contains 75 JPEG files and 75 XML files.\n",
            "The folder tommy_hilfiger contains 49 JPEG files and 49 XML files.\n",
            "The folder Hugo_Boss contains 46 JPEG files and 46 XML files.\n",
            "The folder timberland contains 96 JPEG files and 96 XML files.\n",
            "The folder polo_ralph_lauren contains 21 JPEG files and 21 XML files.\n",
            "The folder Armani contains 81 JPEG files and 81 XML files.\n",
            "The folder louis_vuitton_2 contains 96 JPEG files and 96 XML files.\n",
            "The folder the_north_face contains 118 JPEG files and 118 XML files.\n",
            "The folder Ellesse contains 51 JPEG files and 51 XML files.\n",
            "The folder chanel contains 25 JPEG files and 25 XML files.\n",
            "The folder Chloe contains 33 JPEG files and 33 XML files.\n",
            "The folder napapijri contains 80 JPEG files and 80 XML files.\n"
          ]
        }
      ],
      "source": [
        "# Main directory path\n",
        "main_directory = '/content/Dataset/Clothes'\n",
        "\n",
        "# Function to count files with a specific extension in a directory\n",
        "def count_files(directory, extension):\n",
        "    # Use glob to find all files with the specified extension\n",
        "    files = glob(os.path.join(directory, f'*.{extension.lower()}'))\n",
        "    number_of_files = len(files)\n",
        "    return number_of_files\n",
        "\n",
        "# Iterate through all folders in the main directory\n",
        "for subdirectory in os.listdir(main_directory):\n",
        "    subdirectory_path = os.path.join(main_directory, subdirectory)\n",
        "\n",
        "    # Check if it's a directory\n",
        "    if os.path.isdir(subdirectory_path):\n",
        "        # Count JPEG files in this directory\n",
        "        number_of_jpeg = count_files(subdirectory_path, 'jpeg') + count_files(subdirectory_path, 'jpg')\n",
        "\n",
        "        # Count XML files in this directory\n",
        "        number_of_xml = count_files(subdirectory_path, 'xml')\n",
        "\n",
        "        # Display the result\n",
        "        print(f\"The folder {subdirectory} contains {number_of_jpeg} JPEG files and {number_of_xml} XML files.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "IsWpiB0xbNis",
      "metadata": {
        "id": "IsWpiB0xbNis"
      },
      "outputs": [],
      "source": [
        "def count_files(directory, extension):\n",
        "    files = glob(os.path.join(directory, f'*.{extension}'))\n",
        "    number_of_files = len(files)\n",
        "    return number_of_files\n",
        "\n",
        "def duplicate_files(folder_path, target_count_per_folder):\n",
        "    for subfolder in os.listdir(folder_path):\n",
        "        subfolder_path = os.path.join(folder_path, subfolder)\n",
        "\n",
        "        if os.path.isdir(subfolder_path):\n",
        "            # Calculate the number of images to duplicate to reach at least target_count_per_folder\n",
        "            images_to_duplicate = max(0, target_count_per_folder - count_files(subfolder_path, 'jpg'))\n",
        "\n",
        "            # Duplicate files if necessary\n",
        "            for i in range(images_to_duplicate):\n",
        "                # New names for duplicated files\n",
        "                new_image_number = images_to_duplicate + i + 1\n",
        "                new_image_name = f\"{new_image_number}_{subfolder}.jpg\"\n",
        "                new_xml_name = f\"{new_image_number}_{subfolder}.xml\"\n",
        "                new_image_path = os.path.join(subfolder_path, new_image_name)\n",
        "                new_xml_path = os.path.join(subfolder_path, new_xml_name)\n",
        "\n",
        "                # Use a random image and XML file for duplication\n",
        "                source_image_path = random.choice(glob(os.path.join(subfolder_path, '*.jpg')))\n",
        "                source_xml_path = source_image_path.replace('.jpg', '.xml')\n",
        "\n",
        "                # Check if the source file is different from the destination file\n",
        "                if source_image_path != new_image_path:\n",
        "                    shutil.copy(source_image_path, new_image_path)\n",
        "                if source_xml_path != new_xml_path:\n",
        "                    shutil.copy(source_xml_path, new_xml_path)\n",
        "\n",
        "folder_path = \"/content/Dataset/Clothes\"\n",
        "target_count_per_folder = 150\n",
        "duplicate_files(folder_path, target_count_per_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14eafde2-4ad3-48ab-a548-7023afe4d596",
      "metadata": {
        "id": "14eafde2-4ad3-48ab-a548-7023afe4d596"
      },
      "source": [
        "## Creation of the Dataset (train, test, valid) and the YALM file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "2408eeb9-67d5-43ba-9ccb-60efadda882a",
      "metadata": {
        "id": "2408eeb9-67d5-43ba-9ccb-60efadda882a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Path to the main folder\n",
        "main_folder = '/content/Dataset/Clothes'\n",
        "\n",
        "# Create the folder structure for the Dataset\n",
        "dataset_folder = '/content/Dataset'\n",
        "folders = ['train', 'test', 'valid']\n",
        "subfolders = ['images', 'labels']\n",
        "\n",
        "# Create the folder structure\n",
        "for folder in folders:\n",
        "    for subfolder in subfolders:\n",
        "        path = os.path.join(dataset_folder, folder, subfolder)\n",
        "        os.makedirs(path, exist_ok=True)\n",
        "\n",
        "# Get the list of all brand folders in your Clothes folder\n",
        "brand_folders = [f for f in os.listdir(main_folder) if os.path.isdir(os.path.join(main_folder, f))]\n",
        "num_classes = len(brand_folders)\n",
        "\n",
        "# Initialize variables outside the loop\n",
        "all_train_files = []\n",
        "all_test_files = []\n",
        "all_valid_files = []\n",
        "\n",
        "# Split data into train, test, and validation sets for each brand\n",
        "for brand_folder in brand_folders:\n",
        "    brand_path = os.path.join(main_folder, brand_folder)\n",
        "    image_files = [f for f in os.listdir(brand_path) if f.endswith('.jpg')]\n",
        "\n",
        "    # Ensure there are enough samples for the split\n",
        "    if len(image_files) < 5:\n",
        "        print(f\"Assigning all samples from {brand_folder} to the training set due to insufficient samples.\")\n",
        "        train_files = image_files\n",
        "        test_files = []\n",
        "        valid_files = []\n",
        "    else:\n",
        "        # Split into train and test_valid_files\n",
        "        train_files, test_valid_files = train_test_split(image_files, test_size=0.2, random_state=43)\n",
        "\n",
        "        # Check if test_valid_files has enough samples\n",
        "        if len(test_valid_files) < 2:\n",
        "            train_files.extend(test_valid_files)\n",
        "            test_files = []\n",
        "            valid_files = []\n",
        "        else:\n",
        "            # Split test_valid_files into test and validation\n",
        "            test_files, valid_files = train_test_split(test_valid_files, test_size=0.5, random_state=43)\n",
        "\n",
        "    # Add files from each brand to the overall list\n",
        "    all_train_files.extend(train_files)\n",
        "    all_test_files.extend(test_files)\n",
        "    all_valid_files.extend(valid_files)\n",
        "\n",
        "    # Move files to the corresponding folders\n",
        "    def move_files(source_folder, destination_folder, file_list):\n",
        "        for file in file_list:\n",
        "            image_path = os.path.join(brand_path, file)\n",
        "            xml_path = os.path.join(brand_path, os.path.splitext(file)[0] + '.xml')\n",
        "\n",
        "            dest_image_path = os.path.join(dataset_folder, destination_folder, 'images', file)\n",
        "            dest_xml_path = os.path.join(dataset_folder, destination_folder, 'labels', os.path.splitext(file)[0] + '.xml')\n",
        "\n",
        "            shutil.copy(image_path, dest_image_path)\n",
        "            shutil.copy(xml_path, dest_xml_path)\n",
        "\n",
        "    # Move files to the corresponding folders\n",
        "    move_files(brand_folder, 'train', train_files)\n",
        "    move_files(brand_folder, 'test', test_files)\n",
        "    move_files(brand_folder, 'valid', valid_files)\n",
        "\n",
        "# Create a YAML file for YOLO\n",
        "yolo_yaml_content = \"names:\\n\"\n",
        "\n",
        "for idx, brand_name in enumerate(brand_folders):\n",
        "    yolo_yaml_content += f\"  {idx}: {brand_name}\\n\"\n",
        "\n",
        "yolo_yaml_content += f\"\"\"\n",
        "train: {os.path.join(dataset_folder, 'train/images')}\n",
        "val: {os.path.join(dataset_folder, 'valid/images')}\n",
        "test: {os.path.join(dataset_folder, 'test/images')}\n",
        "\n",
        "nc: {num_classes}\n",
        "\"\"\"\n",
        "\n",
        "with open('/content/Dataset/data.yaml', 'w') as yaml_file:\n",
        "    yaml_file.write(yolo_yaml_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pNkOMMm_4Ulr",
      "metadata": {
        "id": "pNkOMMm_4Ulr"
      },
      "source": [
        "## Converting XML files to TXT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "oxE0DPQY9TWf",
      "metadata": {
        "id": "oxE0DPQY9TWf"
      },
      "outputs": [],
      "source": [
        "# Load the YAML file with names and associated IDs\n",
        "with open('/content/Dataset/data.yaml', 'r') as yaml_file:\n",
        "    yaml_content = yaml.load(yaml_file, Loader=yaml.FullLoader)\n",
        "\n",
        "class_ids = {v: k for k, v in yaml_content['names'].items()}\n",
        "\n",
        "def convert_xml_to_yolov8(xml_path, output_path):\n",
        "    tree = ET.parse(xml_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    image_width = int(root.find(\".//size/width\").text)\n",
        "    image_height = int(root.find(\".//size/height\").text)\n",
        "\n",
        "    with open(output_path, 'w') as output_file:\n",
        "        for obj in root.findall(\".//object\"):\n",
        "            raw_class_name = obj.find(\"name\").text\n",
        "            # Replace spaces with underscores\n",
        "            class_name = raw_class_name.replace(\" \", \"_\")\n",
        "            class_name = class_name.replace(\"-\", \"_\")\n",
        "            class_name = class_name.replace(\"'\", \"_\")\n",
        "            class_name = class_name.replace(\"76\", \"A_76\")\n",
        "            class_name = class_name.replace(\"snow_peak_2\", \"timbuk2_1\")\n",
        "            class_name = class_name.replace(\"Alcatel_2\", \"alpinestars_2\")\n",
        "            class_name = class_name.replace(\"maybach_1\", \"meyba_1\")\n",
        "            class_name = class_name.replace(\"INOHERB_2\", \"Isabel_Maran_2\")\n",
        "            class_name = class_name.replace(\"Harvest_Moon\", \"Heat_1\")\n",
        "            class_name = class_name.replace(\"Alcatel_2\", \"alpinestars_2\")\n",
        "            class_name = class_name.replace(\"Alcatel_2\", \"alpinestars_2\")\n",
        "            class_name = class_name.replace(\"Alcatel_2\", \"alpinestars_2\")\n",
        "            class_name = class_name.replace(\"Alcatel_2\", \"alpinestars_2\")\n",
        "            class_name = class_name.replace(\"Alcatel_2\", \"alpinestars_2\")\n",
        "            class_name = class_name.replace(\"Alcatel_2\", \"alpinestars_2\")\n",
        "            class_name = class_name.replace(\"Alcatel_2\", \"alpinestars_2\")\n",
        "\n",
        "            # Use the get method with a default value of -1\n",
        "            class_id = class_ids.get(class_name, -1)\n",
        "\n",
        "            # Check if the class was found\n",
        "            if class_id == -1:\n",
        "                print(f\"Class not found for {class_name} in the file {xml_path}\")\n",
        "                continue\n",
        "\n",
        "            xmin = int(obj.find(\"bndbox/xmin\").text)\n",
        "            ymin = int(obj.find(\"bndbox/ymin\").text)\n",
        "            xmax = int(obj.find(\"bndbox/xmax\").text)\n",
        "            ymax = int(obj.find(\"bndbox/ymax\").text)\n",
        "\n",
        "            center_x = (xmin + xmax) / (2.0 * image_width)\n",
        "            center_y = (ymin + ymax) / (2.0 * image_height)\n",
        "            bbox_width = (xmax - xmin) / image_width\n",
        "            bbox_height = (ymax - ymin) / image_height\n",
        "\n",
        "            output_line = f\"{class_id} {center_x} {center_y} {bbox_width} {bbox_height}\\n\"\n",
        "            output_file.write(output_line)\n",
        "\n",
        "def process_xml_folder(xml_folder):\n",
        "    yolov8_output_folder = xml_folder  # Same output folder as the input folder\n",
        "\n",
        "    # Ensure the output folder exists\n",
        "    os.makedirs(yolov8_output_folder, exist_ok=True)\n",
        "\n",
        "    # Conversion for each XML file\n",
        "    for xml_file in os.listdir(xml_folder):\n",
        "        if xml_file.endswith(\".xml\"):\n",
        "            xml_path = os.path.join(xml_folder, xml_file)\n",
        "            yolov8_output_path = os.path.join(yolov8_output_folder, xml_file.replace(\".xml\", \".txt\"))\n",
        "            convert_xml_to_yolov8(xml_path, yolov8_output_path)\n",
        "\n",
        "            # Remove the XML file after conversion\n",
        "            os.remove(xml_path)\n",
        "\n",
        "# Folders to process\n",
        "input_folders = [\n",
        "    '/content/Dataset/train/labels',\n",
        "    '/content/Dataset/valid/labels',\n",
        "    '/content/Dataset/test/labels'\n",
        "]\n",
        "\n",
        "# Process each XML folder\n",
        "for xml_folder in input_folders:\n",
        "    process_xml_folder(xml_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07eb530d-d68f-41c9-b1d4-03f2309558fa",
      "metadata": {
        "id": "07eb530d-d68f-41c9-b1d4-03f2309558fa"
      },
      "source": [
        "## Loading the YOLO version 8 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "558898ba-29f2-4be7-9461-a7ac33a71320",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "558898ba-29f2-4be7-9461-a7ac33a71320",
        "outputId": "bf80a28d-c877-4436-e207-3172b6e5608b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K\r\u001b[2K\rUltralytics YOLOv8.0.235 ðŸš€ Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 30.4/78.2 GB disk)\n",
            "\n",
            "OS                  Linux-6.1.58+-x86_64-with-glibc2.35\n",
            "Environment         Colab\n",
            "Python              3.10.12\n",
            "Install             pip\n",
            "RAM                 12.67 GB\n",
            "CPU                 Intel Xeon 2.20GHz\n",
            "CUDA                12.1\n",
            "\n",
            "matplotlib          âœ… 3.7.1>=3.3.0\n",
            "numpy               âœ… 1.23.5>=1.22.2\n",
            "opencv-python       âœ… 4.8.0.76>=4.6.0\n",
            "pillow              âœ… 9.4.0>=7.1.2\n",
            "pyyaml              âœ… 6.0.1>=5.3.1\n",
            "requests            âœ… 2.31.0>=2.23.0\n",
            "scipy               âœ… 1.11.4>=1.4.1\n",
            "torch               âœ… 2.1.0+cu121>=1.8.0\n",
            "torchvision         âœ… 0.16.0+cu121>=0.9.0\n",
            "tqdm                âœ… 4.66.1>=4.64.0\n",
            "psutil              âœ… 5.9.5\n",
            "py-cpuinfo          âœ… 9.0.0\n",
            "thop                âœ… 0.1.1-2209072238>=0.1.1\n",
            "pandas              âœ… 1.5.3>=1.1.4\n",
            "seaborn             âœ… 0.12.2>=0.11.0\n"
          ]
        }
      ],
      "source": [
        "# Clear the output in Jupyter Notebook\n",
        "display.clear_output()\n",
        "\n",
        "# Your YOLO command\n",
        "!yolo checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "a7de0006-1567-4acb-bdba-1076865d2f9b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7de0006-1567-4acb-bdba-1076865d2f9b",
        "outputId": "bc1400a4-0838-4a41-bd23-735565de96fd",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
            "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
            " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
            " 22        [15, 18, 21]  1   3822016  ultralytics.nn.modules.head.Detect           [80, [192, 384, 576]]         \n",
            "YOLOv8m summary: 295 layers, 25902640 parameters, 25902624 gradients, 79.3 GFLOPs\n",
            "\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m.pt to 'yolov8m.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49.7M/49.7M [00:00<00:00, 218MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Load a model\n",
        "model = YOLO(\"yolov8m.yaml\")  # build a new model from scratch\n",
        "model = YOLO(\"yolov8m.pt\")  # load a pretrained model (recommended for training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "2-WEaxsvbVXI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-WEaxsvbVXI",
        "outputId": "7c144850-bfd9-4a97-9d95-f9423a8bf4e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.235 ðŸš€ Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/content/yolov8m.pt, data=/content/Dataset/data.yaml, epochs=30, time=None, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
            "100% 755k/755k [00:00<00:00, 25.6MB/s]\n",
            "2024-01-05 14:07:03.781074: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-05 14:07:03.781182: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-05 14:07:03.884504: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Overriding model.yaml nc=80 with nc=45\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
            "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
            " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
            " 22        [15, 18, 21]  1   3801751  ultralytics.nn.modules.head.Detect           [45, [192, 384, 576]]         \n",
            "Model summary: 295 layers, 25882375 parameters, 25882359 gradients, 79.2 GFLOPs\n",
            "\n",
            "Transferred 469/475 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n",
            "100% 6.23M/6.23M [00:00<00:00, 122MB/s]\n",
            "WARNING âš ï¸ NMS time limit 0.550s exceeded\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Dataset/train/labels... 5101 images, 0 backgrounds, 0 corrupt: 100% 5101/5101 [00:04<00:00, 1112.35it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/Dataset/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Dataset/valid/labels... 648 images, 0 backgrounds, 0 corrupt: 100% 648/648 [00:00<00:00, 1165.04it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Dataset/valid/labels.cache\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000204, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
            "30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/30      6.96G      1.183      3.346      1.391         40        640: 100% 319/319 [02:50<00:00,  1.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 21/21 [00:10<00:00,  2.00it/s]\n",
            "                   all        648        801      0.763       0.65      0.725      0.524\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/30      7.18G     0.9979      1.652      1.221         33        640: 100% 319/319 [02:46<00:00,  1.91it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 21/21 [00:07<00:00,  2.76it/s]\n",
            "                   all        648        801      0.749      0.696      0.779      0.563\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/30      7.18G     0.9684      1.362      1.196         39        640: 100% 319/319 [02:45<00:00,  1.92it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 21/21 [00:08<00:00,  2.54it/s]\n",
            "                   all        648        801      0.735      0.832      0.857      0.642\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/30      7.18G     0.9375      1.169      1.177         41        640: 100% 319/319 [02:44<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 21/21 [00:08<00:00,  2.56it/s]\n",
            "                   all        648        801      0.836      0.805      0.878      0.668\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/30      7.16G     0.8939      1.057       1.15         42        640: 100% 319/319 [02:45<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 21/21 [00:08<00:00,  2.55it/s]\n",
            "                   all        648        801       0.87      0.821      0.901       0.71\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/30       7.2G     0.8497     0.9181      1.121         53        640: 100% 319/319 [02:45<00:00,  1.92it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 21/21 [00:08<00:00,  2.41it/s]\n",
            "                   all        648        801      0.866      0.873      0.905      0.709\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/30      7.18G     0.8147      0.847      1.102         42        640: 100% 319/319 [02:44<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 21/21 [00:08<00:00,  2.48it/s]\n",
            "                   all        648        801      0.889      0.909       0.94       0.76\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/30      7.18G     0.7948     0.7734      1.095         33        640: 100% 319/319 [02:44<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 21/21 [00:07<00:00,  2.93it/s]\n",
            "                   all        648        801      0.901      0.918      0.942       0.76\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/30      7.14G     0.7592     0.7132      1.076         38        640: 100% 319/319 [02:45<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 21/21 [00:08<00:00,  2.52it/s]\n",
            "                   all        648        801      0.926      0.891      0.946      0.773\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/30      7.19G     0.7308     0.6708      1.058         38        640: 100% 319/319 [02:45<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 21/21 [00:07<00:00,  2.91it/s]\n",
            "                   all        648        801      0.928      0.929       0.95      0.775\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/30      7.18G     0.7117     0.6385       1.05         35        640: 100% 319/319 [02:44<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 21/21 [00:07<00:00,  2.82it/s]\n",
            "                   all        648        801      0.914      0.945      0.953      0.793\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/30      7.17G     0.6854     0.5953      1.039         28        640: 100% 319/319 [02:45<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 21/21 [00:08<00:00,  2.44it/s]\n",
            "                   all        648        801      0.943      0.931      0.957      0.806\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/30      7.14G     0.6664     0.5681      1.026         26        640: 100% 319/319 [02:45<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 21/21 [00:08<00:00,  2.51it/s]\n",
            "                   all        648        801       0.94      0.941      0.962      0.812\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/30      7.18G     0.6602     0.5614      1.027         38        640: 100% 319/319 [02:44<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 21/21 [00:08<00:00,  2.62it/s]\n",
            "                   all        648        801      0.944      0.942      0.962       0.82\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/30       7.2G     0.6412       0.53      1.013         33        640: 100% 319/319 [02:44<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 21/21 [00:07<00:00,  2.71it/s]\n",
            "                   all        648        801      0.961      0.935      0.964      0.825\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/30      7.18G        inf     0.5091      1.007         25        640: 100% 319/319 [02:43<00:00,  1.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 21/21 [00:07<00:00,  2.94it/s]\n",
            "                   all        648        801      0.946      0.952      0.963      0.835\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/30      7.15G     0.6051     0.4821     0.9978         36        640: 100% 319/319 [02:42<00:00,  1.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 21/21 [00:07<00:00,  2.81it/s]\n",
            "                   all        648        801      0.949      0.947      0.966       0.84\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/30      7.18G     0.5897     0.4569     0.9896         39        640: 100% 319/319 [02:43<00:00,  1.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 21/21 [00:08<00:00,  2.57it/s]\n",
            "                   all        648        801      0.954      0.953      0.966       0.85\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/30      7.19G      0.573     0.4495     0.9836         38        640: 100% 319/319 [02:43<00:00,  1.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 21/21 [00:08<00:00,  2.35it/s]\n",
            "                   all        648        801      0.953       0.95      0.968      0.854\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/30      7.17G     0.5538     0.4339     0.9768         33        640: 100% 319/319 [02:43<00:00,  1.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 21/21 [00:07<00:00,  2.94it/s]\n",
            "                   all        648        801      0.936      0.953      0.966      0.854\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      21/30      7.15G     0.5049     0.3363     0.9384         14        640: 100% 319/319 [02:43<00:00,  1.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 21/21 [00:07<00:00,  2.71it/s]\n",
            "                   all        648        801      0.958      0.952      0.966      0.853\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      22/30       7.2G     0.4821     0.3123     0.9241         16        640: 100% 319/319 [02:41<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 21/21 [00:07<00:00,  2.83it/s]\n",
            "                   all        648        801      0.957       0.96      0.972       0.86\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      23/30      7.19G     0.4724     0.2999     0.9168         15        640: 100% 319/319 [02:41<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 21/21 [00:08<00:00,  2.47it/s]\n",
            "                   all        648        801      0.963      0.947      0.972      0.866\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      24/30      7.17G     0.4489     0.2853      0.905         18        640: 100% 319/319 [02:41<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 21/21 [00:07<00:00,  2.77it/s]\n",
            "                   all        648        801      0.971      0.958      0.975      0.875\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      25/30      7.16G     0.4366     0.2733     0.9037         16        640: 100% 319/319 [02:41<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 21/21 [00:07<00:00,  2.83it/s]\n",
            "                   all        648        801      0.969      0.953      0.973      0.878\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      26/30      7.18G     0.4219     0.2608     0.8941         16        640: 100% 319/319 [02:41<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 21/21 [00:07<00:00,  2.79it/s]\n",
            "                   all        648        801      0.956      0.962      0.974      0.886\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      27/30      7.19G     0.4019     0.2483     0.8865         15        640: 100% 319/319 [02:41<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 21/21 [00:09<00:00,  2.28it/s]\n",
            "                   all        648        801      0.975      0.961      0.978      0.894\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      28/30      7.18G     0.3875     0.2356     0.8798         16        640: 100% 319/319 [02:41<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 21/21 [00:08<00:00,  2.60it/s]\n",
            "                   all        648        801       0.98      0.951      0.978      0.895\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      29/30      7.16G     0.3808     0.2269     0.8717         14        640: 100% 319/319 [02:42<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 21/21 [00:07<00:00,  2.78it/s]\n",
            "                   all        648        801      0.978      0.954      0.978      0.897\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      30/30      7.18G     0.3656     0.2197     0.8721         18        640: 100% 319/319 [02:41<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 21/21 [00:07<00:00,  2.68it/s]\n",
            "                   all        648        801      0.972      0.954      0.977      0.899\n",
            "\n",
            "30 epochs completed in 1.535 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 52.1MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 52.1MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.0.235 ðŸš€ Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 218 layers, 25865815 parameters, 0 gradients, 78.8 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 21/21 [00:10<00:00,  1.98it/s]\n",
            "                   all        648        801      0.972      0.954      0.977      0.899\n",
            "             Adidas_SB        648         17      0.997      0.882      0.907      0.776\n",
            "                Celine        648         12      0.972      0.917      0.989      0.796\n",
            "         new_balance_1        648         32      0.993          1      0.995      0.941\n",
            "         new_balance_2        648         21      0.988          1      0.995      0.913\n",
            "               Bulgari        648         13      0.986          1      0.995      0.908\n",
            "              Carhartt        648         15      0.983      0.933      0.991      0.968\n",
            "              Everlast        648         15      0.962          1      0.995       0.96\n",
            "                  zara        648         19          1      0.885      0.995      0.663\n",
            "                 Guess        648         19       0.99          1      0.995      0.962\n",
            "       sergio_tacchini        648         15      0.993          1      0.995      0.995\n",
            "       louis_vuitton_1        648         11      0.981          1      0.995      0.957\n",
            "               lacoste        648         15      0.989          1      0.995      0.934\n",
            "                 prada        648         15      0.987          1      0.995      0.905\n",
            "              Champion        648         17      0.986      0.941      0.968      0.947\n",
            "                 Kenzo        648         15      0.986          1      0.995      0.954\n",
            "                 levis        648         23      0.903      0.826      0.885      0.834\n",
            "                   Gap        648         21      0.953          1      0.993      0.922\n",
            "                uniqlo        648         23      0.952      0.868      0.934      0.715\n",
            "     Ck_Calvin_Klein_1        648         32      0.992          1      0.995      0.995\n",
            "               oxxford        648         15      0.988          1      0.995      0.904\n",
            "        the_timberland        648         15      0.769      0.667      0.798      0.764\n",
            "               Giorgio        648         15      0.986          1      0.995      0.979\n",
            "        American_Eagle        648         23       0.99      0.957      0.969      0.954\n",
            "            Balenciaga        648         19      0.901       0.96      0.941      0.858\n",
            "             patagonia        648         14      0.994          1      0.995      0.801\n",
            "     Ck_Calvin_Klein_2        648         32      0.999          1      0.995      0.916\n",
            "            pepe_jeans        648         14      0.921          1      0.995      0.913\n",
            "                 Casio        648         15      0.985          1      0.995      0.964\n",
            "              Columbia        648         15      0.987          1      0.995      0.951\n",
            "              Converse        648         15      0.986          1      0.995      0.971\n",
            "               versace        648         21      0.965          1      0.995      0.976\n",
            "                 rolex        648         16      0.935          1      0.995       0.94\n",
            "              tom_ford        648         15      0.985          1      0.995      0.989\n",
            "                  obey        648         29          1      0.987      0.995      0.892\n",
            "        tommy_hilfiger        648         20          1      0.742      0.929      0.828\n",
            "             Hugo_Boss        648         15      0.986          1      0.995       0.97\n",
            "            timberland        648         13       0.88      0.568      0.857      0.791\n",
            "     polo_ralph_lauren        648         15       0.99          1      0.995      0.987\n",
            "                Armani        648         17          1      0.922      0.995      0.883\n",
            "       louis_vuitton_2        648         23      0.994          1      0.995      0.823\n",
            "        the_north_face        648         16      0.987          1      0.995      0.803\n",
            "               Ellesse        648         15      0.927      0.933      0.956      0.798\n",
            "                chanel        648         15          1      0.959      0.995      0.991\n",
            "                 Chloe        648         15      0.985          1      0.995      0.812\n",
            "             napapijri        648         14      0.989          1      0.995      0.965\n",
            "Speed: 0.2ms preprocess, 7.7ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n",
            "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ],
      "source": [
        "!yolo task=detect mode=train model=/content/yolov8m.pt data=/content/Dataset/data.yaml epochs = 30 imgsz = 640"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "1399a5e7-6657-469d-ac9c-3935d5992af7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1399a5e7-6657-469d-ac9c-3935d5992af7",
        "outputId": "97e3b193-d866-4a08-dbeb-124e0f49399b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.235 ðŸš€ Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 218 layers, 25865815 parameters, 0 gradients, 78.8 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Dataset/valid/labels.cache... 648 images, 0 backgrounds, 0 corrupt: 100% 648/648 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 41/41 [00:14<00:00,  2.74it/s]\n",
            "                   all        648        801      0.972      0.954      0.977        0.9\n",
            "             Adidas_SB        648         17      0.995      0.882      0.907       0.78\n",
            "                Celine        648         12      0.972      0.917      0.989      0.808\n",
            "         new_balance_1        648         32      0.993          1      0.995      0.941\n",
            "         new_balance_2        648         21      0.988          1      0.995      0.924\n",
            "               Bulgari        648         13      0.986          1      0.995      0.908\n",
            "              Carhartt        648         15      0.983      0.933      0.988      0.966\n",
            "              Everlast        648         15      0.962          1      0.995       0.96\n",
            "                  zara        648         19          1      0.886      0.995      0.661\n",
            "                 Guess        648         19       0.99          1      0.995      0.962\n",
            "       sergio_tacchini        648         15      0.993          1      0.995      0.995\n",
            "       louis_vuitton_1        648         11      0.981          1      0.995      0.956\n",
            "               lacoste        648         15      0.988          1      0.995      0.934\n",
            "                 prada        648         15      0.987          1      0.995      0.905\n",
            "              Champion        648         17      0.986      0.941      0.968      0.947\n",
            "                 Kenzo        648         15      0.986          1      0.995      0.953\n",
            "                 levis        648         23      0.903      0.826      0.885      0.834\n",
            "                   Gap        648         21      0.953          1      0.993       0.92\n",
            "                uniqlo        648         23      0.952      0.868      0.934      0.734\n",
            "     Ck_Calvin_Klein_1        648         32      0.992          1      0.995      0.995\n",
            "               oxxford        648         15      0.988          1      0.995      0.904\n",
            "        the_timberland        648         15      0.769      0.667      0.798      0.764\n",
            "               Giorgio        648         15      0.986          1      0.995      0.979\n",
            "        American_Eagle        648         23      0.989      0.957      0.969      0.953\n",
            "            Balenciaga        648         19      0.901      0.961      0.941      0.862\n",
            "             patagonia        648         14      0.994          1      0.995      0.801\n",
            "     Ck_Calvin_Klein_2        648         32      0.999          1      0.995       0.91\n",
            "            pepe_jeans        648         14      0.921          1      0.995      0.914\n",
            "                 Casio        648         15      0.985          1      0.995      0.963\n",
            "              Columbia        648         15      0.987          1      0.995      0.951\n",
            "              Converse        648         15      0.986          1      0.995      0.971\n",
            "               versace        648         21      0.964          1      0.995      0.976\n",
            "                 rolex        648         16      0.935          1      0.995       0.94\n",
            "              tom_ford        648         15      0.985          1      0.995      0.989\n",
            "                  obey        648         29          1      0.987      0.995      0.894\n",
            "        tommy_hilfiger        648         20          1      0.742      0.929      0.828\n",
            "             Hugo_Boss        648         15      0.986          1      0.995       0.97\n",
            "            timberland        648         13      0.881       0.57      0.857      0.796\n",
            "     polo_ralph_lauren        648         15       0.99          1      0.995      0.973\n",
            "                Armani        648         17          1      0.923      0.995      0.883\n",
            "       louis_vuitton_2        648         23      0.994          1      0.995      0.823\n",
            "        the_north_face        648         16      0.986          1      0.995      0.804\n",
            "               Ellesse        648         15      0.927      0.933      0.956      0.797\n",
            "                chanel        648         15          1      0.959      0.995      0.991\n",
            "                 Chloe        648         15      0.985          1      0.995      0.804\n",
            "             napapijri        648         14      0.989          1      0.995      0.963\n",
            "Speed: 0.4ms preprocess, 15.8ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val\u001b[0m\n",
            "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/val\n"
          ]
        }
      ],
      "source": [
        "!yolo task=detect mode=val model=/content/runs/detect/train/weights/best.pt data=/content/Dataset/data.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KWz7CV9jVZYV",
      "metadata": {
        "id": "KWz7CV9jVZYV"
      },
      "source": [
        "## Logo detection on a list of sample videos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "w3nZisYXC2y3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3nZisYXC2y3",
        "outputId": "95ec6fcf-b98d-48f8-b30b-b434e3ef81ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  XNF1dlHlOd0 -U3vC3swKAo tWPu7SHJOKM\n",
            "Adidas_SB                 Yes         Yes          No\n",
            "American_Eagle             No          No          No\n",
            "Armani                     No          No          No\n",
            "Balenciaga                 No         Yes          No\n",
            "Bulgari                   Yes          No          No\n",
            "Ck_Calvin_Klein_1          No          No          No\n",
            "Ck_Calvin_Klein_2          No          No          No\n",
            "Canada Goose               No          No          No\n",
            "Carhartt                   No          No          No\n",
            "Casio                      No          No          No\n",
            "Celine                     No         Yes          No\n",
            "Champion                   No          No          No\n",
            "chanel                     No          No          No\n",
            "Chloe                      No          No          No\n",
            "Columbia                  Yes          No          No\n",
            "Converse                   No          No          No\n",
            "Ellesse                   Yes         Yes         Yes\n",
            "Everlast                   No          No         Yes\n",
            "Gap                        No          No          No\n",
            "Giorgio                    No          No          No\n",
            "Guess                     Yes          No          No\n",
            "Hugo_Boss                  No          No          No\n",
            "Karl_Lagerfield            No          No          No\n",
            "Kenzo                     Yes          No          No\n",
            "lacoste                    No          No          No\n",
            "levis                      No         Yes         Yes\n",
            "louis_vuitton_1            No          No          No\n",
            "louis_vuitton_2            No          No          No\n",
            "napapijri                  No          No          No\n",
            "new_balance_1              No          No          No\n",
            "new_balance_2              No         Yes          No\n",
            "obey                       No         Yes          No\n",
            "oxxford                    No          No          No\n",
            "patagonia                  No          No          No\n",
            "pepe_jeans                 No          No          No\n",
            "polo_ralph_lauren          No          No          No\n",
            "prada                      No          No          No\n",
            "rolex                      No          No          No\n",
            "sergio_tacchini            No          No          No\n",
            "the_timberland             No          No          No\n",
            "the_north_face             No          No         Yes\n",
            "timberland                 No          No         Yes\n",
            "tommy_hilfiger            Yes         Yes          No\n",
            "tom_ford                   No          No          No\n",
            "uniqlo                    Yes         Yes          No\n",
            "versace                    No          No          No\n",
            "zara                       No          No         Yes\n"
          ]
        }
      ],
      "source": [
        "# Function to convert processed videos to mp4 format\n",
        "def convert_avi_to_mp4(input_video_path, output_video_path):\n",
        "    input_video = cv2.VideoCapture(input_video_path)\n",
        "    width = int(input_video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(input_video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = input_video.get(cv2.CAP_PROP_FPS)\n",
        "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "    output_video = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "    while True:\n",
        "        ret, frame = input_video.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        output_video.write(frame)\n",
        "\n",
        "    input_video.release()\n",
        "    output_video.release()\n",
        "\n",
        "# Function to detect folders starting with 'predict' where processed videos are saved\n",
        "def process_detect_folders(detect_path):\n",
        "    for folder_name in os.listdir(detect_path):\n",
        "        folder_path = os.path.join(detect_path, folder_name)\n",
        "\n",
        "        if os.path.isdir(folder_path) and folder_name.startswith(\"predict\"):\n",
        "            for file_name in os.listdir(folder_path):\n",
        "                file_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "                if os.path.isfile(file_path) and file_name.lower().endswith(\".avi\"):\n",
        "                    # Create an output path with the same filename but with the .mp4 extension\n",
        "                    mp4_path = os.path.join(folder_path, file_name.lower().replace(\".avi\", \".mp4\"))\n",
        "\n",
        "                    # Convert AVI video to MP4\n",
        "                    convert_avi_to_mp4(file_path, mp4_path)\n",
        "\n",
        "                    # Remove the AVI file after conversion\n",
        "                    os.remove(file_path)\n",
        "\n",
        "# List of your videos\n",
        "video_urls = [\n",
        "    \"https://youtu.be/XNF1dlHlOd0?si=0dOK_xMNDRHXJqIB\",\n",
        "    \"https://youtube.com/shorts/-U3vC3swKAo?si=VI2kdgJhBmdhmZWm\",\n",
        "    \"https://youtube.com/shorts/tWPu7SHJOKM?si=cNQpuhSkfqX_ehwj\"\n",
        "]\n",
        "\n",
        "# Folder where original videos are saved\n",
        "save_path = '/content/video_youtube'\n",
        "\n",
        "# Folder to save videos generated by YOLO\n",
        "yolo_save_path = '/content/runs/detect/predict'\n",
        "\n",
        "# Specify the path to the /content/runs/detect folder where folders starting with 'predict' are located\n",
        "detect_folder_path = \"/content/runs/detect\"\n",
        "\n",
        "# Extract video IDs from URLs\n",
        "video_ids = [url.split(\"/\")[-1].split(\"?\")[0] for url in video_urls]\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(index=selected_folders, columns=video_ids)\n",
        "\n",
        "# Loop for each video\n",
        "for video_url in video_urls:\n",
        "    # Download the video\n",
        "    yt = YouTube(video_url)\n",
        "    video_stream = yt.streams.get_highest_resolution()\n",
        "    video_path = video_stream.download(save_path)\n",
        "\n",
        "    # Video ID associated with the video\n",
        "    video_id = video_url.split(\"/\")[-1].split(\"?\")[0]\n",
        "\n",
        "    # Rename the video file with the ID\n",
        "    new_video_name = f'{video_id}.mp4'\n",
        "    new_video_path = os.path.join(save_path, new_video_name)\n",
        "    os.rename(video_path, new_video_path)\n",
        "\n",
        "    # YOLO command\n",
        "    yolo_command = f\"yolo task=detect mode=predict model=/content/runs/detect/train/weights/best.pt source={new_video_path}\"\n",
        "    result_yolo = subprocess.run(yolo_command, shell=True, capture_output=True, text=True)\n",
        "\n",
        "    # Call the function that looks for and converts the processed video to mp4 format\n",
        "    process_detect_folders(detect_folder_path)\n",
        "\n",
        "    # Analyze the content of result_yolo.stdout for each element of each row in the DataFrame\n",
        "    for folder in selected_folders:\n",
        "        if folder in result_yolo.stdout:\n",
        "            df.loc[folder, video_id] = 'Yes'\n",
        "        else:\n",
        "            df.loc[folder, video_id] = 'No'\n",
        "\n",
        "# Display the final DataFrame with results\n",
        "print(df)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
